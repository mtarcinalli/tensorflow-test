{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81bbfb95-ee5d-49d9-ba5e-bbc3c8dfb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:27:59.342194: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-02 16:27:59.362592: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3737fa47-75ab-47fd-b01f-1bfea3f8a2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:28:24.956071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:24.972804: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:24.972871: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4128ba11-8fa6-4af3-9db6-16394c73be59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fbba8a-0409-4a97-9fe0-91d24ddbafee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96d86d9-12e9-4821-9842-cb21fe827577",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "817d7d1f-a105-485f-9d79-835dcbc479ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking images shape\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0233e69-7757-44ce-a7e3-9e235b320a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display single image shape\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "138e72de-1221-42b2-83a3-75b389e90ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking labels\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b04265b-7e66-4096-b509-6aae2211a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling image values between 0-1\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580933d3-6a85-4381-812e-6d469ecb60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding labels\n",
    "y_train_encoded = keras.utils.to_categorical(y_train, num_classes = 10, dtype = 'float32')\n",
    "y_test_encoded = keras.utils.to_categorical(y_test, num_classes = 10, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a510154-4f41-4384-b78d-46b970cefe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "        keras.layers.Dense(3000, activation='relu'),\n",
    "        keras.layers.Dense(1000, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='sigmoid')    \n",
    "    ])\n",
    "    model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acc387ba-ec37-49f2-891f-819962e20fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:28:39.672788: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.673081: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.673245: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.985239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.985313: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.985351: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-06-02 16:28:39.985392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22219 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:28:41.268427: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-06-02 16:28:41.307760: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x563edfad09b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-02 16:28:41.307826: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-06-02 16:28:42.069193: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8901\n",
      "2023-06-02 16:28:43.435100: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 5s 1ms/step - loss: 1.8113 - accuracy: 0.3550\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.6228 - accuracy: 0.4277\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.5427 - accuracy: 0.4558\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.4830 - accuracy: 0.4780\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.4323 - accuracy: 0.4954\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3879 - accuracy: 0.5129\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3511 - accuracy: 0.5266\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3161 - accuracy: 0.5391\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2827 - accuracy: 0.5508\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2544 - accuracy: 0.5609\n",
      "20.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "# GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    model_gpu = get_model()\n",
    "    model_gpu.fit(X_train_scaled, y_train_encoded, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46ca9a86-687b-4e28-9500-f80801be7f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  10/1563 [..............................] - ETA: 18s - loss: 2.4016 - accuracy: 0.0812 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:29:30.081985: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x563ee1b1a1c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-02 16:29:30.082152: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.8131 - accuracy: 0.3545\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.6218 - accuracy: 0.4284\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.5385 - accuracy: 0.4583\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4788 - accuracy: 0.4793\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4323 - accuracy: 0.4934\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3881 - accuracy: 0.5125\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3493 - accuracy: 0.5270\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.3190 - accuracy: 0.5351\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.2833 - accuracy: 0.5494\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.2572 - accuracy: 0.5597\n",
      "2min 26s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "# CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    model_cpu = get_model()\n",
    "    model_cpu.fit(X_train_scaled, y_train_encoded, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4bdbc26-96e1-4b48-9b32-7cc1abb0800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.8200 - accuracy: 0.3524\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.6278 - accuracy: 0.4238\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.5448 - accuracy: 0.4556\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.4852 - accuracy: 0.4762\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.4348 - accuracy: 0.4953\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3912 - accuracy: 0.5117\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3564 - accuracy: 0.5215\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.3184 - accuracy: 0.5365\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2894 - accuracy: 0.5462\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2560 - accuracy: 0.5591\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.2278 - accuracy: 0.5708\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1979 - accuracy: 0.5815\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1721 - accuracy: 0.5886\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1436 - accuracy: 0.5995\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.1173 - accuracy: 0.6110\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0888 - accuracy: 0.6206\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0644 - accuracy: 0.6302\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0377 - accuracy: 0.6391\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 1.0090 - accuracy: 0.6484\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9865 - accuracy: 0.6562\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9600 - accuracy: 0.6685\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9339 - accuracy: 0.6755\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.9102 - accuracy: 0.6839\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8864 - accuracy: 0.6943\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8583 - accuracy: 0.7037\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8316 - accuracy: 0.7130\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.8094 - accuracy: 0.7203\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7825 - accuracy: 0.7287\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7589 - accuracy: 0.7400\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7344 - accuracy: 0.7496\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.7094 - accuracy: 0.7584\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.6854 - accuracy: 0.7678\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.6588 - accuracy: 0.7775\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.6352 - accuracy: 0.7850\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.6123 - accuracy: 0.7946\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.5888 - accuracy: 0.8020\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.5656 - accuracy: 0.8118\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.5406 - accuracy: 0.8203\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.5159 - accuracy: 0.8294\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4936 - accuracy: 0.8394\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4731 - accuracy: 0.8452\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4522 - accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4319 - accuracy: 0.8618\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.4119 - accuracy: 0.8674\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3891 - accuracy: 0.8776\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3709 - accuracy: 0.8819\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3517 - accuracy: 0.8895\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3337 - accuracy: 0.8975\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3199 - accuracy: 0.9007\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.3019 - accuracy: 0.9070\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2822 - accuracy: 0.9156\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2690 - accuracy: 0.9203\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2528 - accuracy: 0.9255\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2372 - accuracy: 0.9324\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2274 - accuracy: 0.9347\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2103 - accuracy: 0.9419\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1961 - accuracy: 0.9465\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1838 - accuracy: 0.9515\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1696 - accuracy: 0.9563\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1603 - accuracy: 0.9593\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1522 - accuracy: 0.9617\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1391 - accuracy: 0.9658\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1328 - accuracy: 0.9679\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1222 - accuracy: 0.9707\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1121 - accuracy: 0.9746\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.1046 - accuracy: 0.9769\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0954 - accuracy: 0.9797\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0947 - accuracy: 0.9798\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0828 - accuracy: 0.9834\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0755 - accuracy: 0.9858\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0689 - accuracy: 0.9875\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0635 - accuracy: 0.9888\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0592 - accuracy: 0.9902\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0552 - accuracy: 0.9906\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0526 - accuracy: 0.9915\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0490 - accuracy: 0.9922\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0431 - accuracy: 0.9939\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0404 - accuracy: 0.9949\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0372 - accuracy: 0.9950\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0352 - accuracy: 0.9958\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0321 - accuracy: 0.9963\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0304 - accuracy: 0.9969\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0303 - accuracy: 0.9961\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0331 - accuracy: 0.9958\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0252 - accuracy: 0.9975\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0245 - accuracy: 0.9975\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0640 - accuracy: 0.9883\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0239 - accuracy: 0.9977\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0208 - accuracy: 0.9980\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0190 - accuracy: 0.9987\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0179 - accuracy: 0.9986\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0162 - accuracy: 0.9989\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0154 - accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0148 - accuracy: 0.9989\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0133 - accuracy: 0.9992\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0131 - accuracy: 0.9992\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0121 - accuracy: 0.9994\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0115 - accuracy: 0.9994\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0111 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.0105 - accuracy: 0.9997\n",
      "2min 44s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "# GPU\n",
    "with tf.device('/GPU:0'):\n",
    "    model_gpu = get_model()\n",
    "    model_gpu.fit(X_train_scaled, y_train_encoded, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1b341-57ac-45f9-bd23-fa0e9e448f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6ab4f-f785-47e3-8c6b-1c32fface4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "807958ec-3401-474e-acc5-31132888db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c787f442-e148-4359-b8bd-ca17ca5378c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# checking shape\n",
    "\n",
    "print(train_images.shape)\n",
    "\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711c35e9-812e-4c77-8cbe-9a223dec16a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking images\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "plt.imshow(train_images[0])\n",
    "class_names[train_labels[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44ea35a9-6294-49cc-8b89-5fde696997d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "train_images_scaled = train_images / 255.0\n",
    "test_images_scaled = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0179913d-ead3-455a-9646-28a76d5efa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layers=1):\n",
    "    # Flatten layer for input\n",
    "    layers = [keras.layers.Flatten(input_shape=(28, 28))]\n",
    "    # hideen layers\n",
    "    for i in range(hidden_layers):\n",
    "        layers.append(keras.layers.Dense(500, activation='relu'),)\n",
    "    # output layer    \n",
    "    layers.append(keras.layers.Dense(10, activation='sigmoid'))\n",
    "    model = keras.Sequential(layers)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7603bf04-2c67-4499-9774-45bb49d142da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  21/1875 [..............................] - ETA: 4s - loss: 1.4557 - accuracy: 0.4405   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:34:41.416927: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 5s 2ms/step - loss: 0.5186 - accuracy: 0.8114\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3926 - accuracy: 0.8578\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3549 - accuracy: 0.8728\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3319 - accuracy: 0.8810\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3107 - accuracy: 0.8868\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2935 - accuracy: 0.8924\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2826 - accuracy: 0.8969\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2687 - accuracy: 0.8997\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2641 - accuracy: 0.9029\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2551 - accuracy: 0.9060\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2446 - accuracy: 0.9079\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2392 - accuracy: 0.9113\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2334 - accuracy: 0.9129\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2269 - accuracy: 0.9163\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2224 - accuracy: 0.9169\n",
      "1min 1s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_model = get_model(hidden_layers=5)\n",
    "    cpu_model.fit(train_images_scaled, train_labels, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08afd08b-b1b4-4cd0-aba7-4b2e6c1b2a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 2s 780us/step - loss: 0.5136 - accuracy: 0.8145\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 2s 828us/step - loss: 0.3903 - accuracy: 0.8597\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 2s 805us/step - loss: 0.3503 - accuracy: 0.8738\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.3282 - accuracy: 0.8805\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.3081 - accuracy: 0.8884\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 2s 800us/step - loss: 0.2950 - accuracy: 0.8920\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.2829 - accuracy: 0.8959\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.2722 - accuracy: 0.9006\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.2635 - accuracy: 0.9023\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.2511 - accuracy: 0.9070\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 2s 822us/step - loss: 0.2468 - accuracy: 0.9084\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 2s 819us/step - loss: 0.2378 - accuracy: 0.9109\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 1s 780us/step - loss: 0.2313 - accuracy: 0.9144\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.2240 - accuracy: 0.9164\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.2208 - accuracy: 0.9175\n",
      "23.4 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with tf.device('/GPU:0'):\n",
    "    gpu_model = get_model(hidden_layers=5)\n",
    "    gpu_model.fit(train_images_scaled, train_labels, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a437b3b6-8763-464a-ae26-57433ede9370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1875/1875 [==============================] - 2s 744us/step - loss: 0.5120 - accuracy: 0.8152\n",
      "Epoch 2/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.3911 - accuracy: 0.8596\n",
      "Epoch 3/300\n",
      "1875/1875 [==============================] - 2s 992us/step - loss: 0.3524 - accuracy: 0.8736\n",
      "Epoch 4/300\n",
      "1875/1875 [==============================] - 2s 930us/step - loss: 0.3264 - accuracy: 0.8819\n",
      "Epoch 5/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.3128 - accuracy: 0.8867\n",
      "Epoch 6/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.2934 - accuracy: 0.8940\n",
      "Epoch 7/300\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.2805 - accuracy: 0.8975\n",
      "Epoch 8/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.2720 - accuracy: 0.8996\n",
      "Epoch 9/300\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.2598 - accuracy: 0.9038\n",
      "Epoch 10/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.2539 - accuracy: 0.9076\n",
      "Epoch 11/300\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.2443 - accuracy: 0.9090\n",
      "Epoch 12/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.2398 - accuracy: 0.9128\n",
      "Epoch 13/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.2324 - accuracy: 0.9128\n",
      "Epoch 14/300\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.2259 - accuracy: 0.9154\n",
      "Epoch 15/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.2212 - accuracy: 0.9167\n",
      "Epoch 16/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.2130 - accuracy: 0.9211\n",
      "Epoch 17/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.2079 - accuracy: 0.9225\n",
      "Epoch 18/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.2044 - accuracy: 0.9248\n",
      "Epoch 19/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1972 - accuracy: 0.9270\n",
      "Epoch 20/300\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.1984 - accuracy: 0.9259\n",
      "Epoch 21/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1877 - accuracy: 0.9297\n",
      "Epoch 22/300\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.1848 - accuracy: 0.9309\n",
      "Epoch 23/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.1837 - accuracy: 0.9315\n",
      "Epoch 24/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.1823 - accuracy: 0.9316\n",
      "Epoch 25/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.1837 - accuracy: 0.9327\n",
      "Epoch 26/300\n",
      "1875/1875 [==============================] - 1s 780us/step - loss: 0.1696 - accuracy: 0.9374\n",
      "Epoch 27/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.1721 - accuracy: 0.9367\n",
      "Epoch 28/300\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.1649 - accuracy: 0.9382\n",
      "Epoch 29/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.1605 - accuracy: 0.9395\n",
      "Epoch 30/300\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.1609 - accuracy: 0.9392\n",
      "Epoch 31/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1700 - accuracy: 0.9397\n",
      "Epoch 32/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.1510 - accuracy: 0.9449\n",
      "Epoch 33/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.1595 - accuracy: 0.9397\n",
      "Epoch 34/300\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.1497 - accuracy: 0.9446\n",
      "Epoch 35/300\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.1463 - accuracy: 0.9458\n",
      "Epoch 36/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.1426 - accuracy: 0.9472\n",
      "Epoch 37/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.1446 - accuracy: 0.9460\n",
      "Epoch 38/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.1578 - accuracy: 0.9439\n",
      "Epoch 39/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.1405 - accuracy: 0.9477\n",
      "Epoch 40/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.1388 - accuracy: 0.9495\n",
      "Epoch 41/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.1316 - accuracy: 0.9506\n",
      "Epoch 42/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.1471 - accuracy: 0.9485\n",
      "Epoch 43/300\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.1280 - accuracy: 0.9523\n",
      "Epoch 44/300\n",
      "1875/1875 [==============================] - 2s 806us/step - loss: 0.1266 - accuracy: 0.9528\n",
      "Epoch 45/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.1358 - accuracy: 0.9513\n",
      "Epoch 46/300\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.1230 - accuracy: 0.9538\n",
      "Epoch 47/300\n",
      "1875/1875 [==============================] - 2s 930us/step - loss: 0.1196 - accuracy: 0.9547\n",
      "Epoch 48/300\n",
      "1875/1875 [==============================] - 1s 759us/step - loss: 0.1291 - accuracy: 0.9528\n",
      "Epoch 49/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1338 - accuracy: 0.9513\n",
      "Epoch 50/300\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.1264 - accuracy: 0.9546\n",
      "Epoch 51/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.1183 - accuracy: 0.9567\n",
      "Epoch 52/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.1196 - accuracy: 0.9574\n",
      "Epoch 53/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.1252 - accuracy: 0.9558\n",
      "Epoch 54/300\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.1077 - accuracy: 0.9597\n",
      "Epoch 55/300\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.1107 - accuracy: 0.9593\n",
      "Epoch 56/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.1318 - accuracy: 0.9546\n",
      "Epoch 57/300\n",
      "1875/1875 [==============================] - 1s 793us/step - loss: 0.1073 - accuracy: 0.9600\n",
      "Epoch 58/300\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.1066 - accuracy: 0.9616\n",
      "Epoch 59/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.1103 - accuracy: 0.9603\n",
      "Epoch 60/300\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.1106 - accuracy: 0.9604\n",
      "Epoch 61/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.1065 - accuracy: 0.9615\n",
      "Epoch 62/300\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.1057 - accuracy: 0.9611\n",
      "Epoch 63/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.1044 - accuracy: 0.9628\n",
      "Epoch 64/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.1224 - accuracy: 0.9604\n",
      "Epoch 65/300\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0909 - accuracy: 0.9660\n",
      "Epoch 66/300\n",
      "1875/1875 [==============================] - 2s 812us/step - loss: 0.0960 - accuracy: 0.9654\n",
      "Epoch 67/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0962 - accuracy: 0.9644\n",
      "Epoch 68/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.0922 - accuracy: 0.9663\n",
      "Epoch 69/300\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.0962 - accuracy: 0.9655\n",
      "Epoch 70/300\n",
      "1875/1875 [==============================] - 1s 773us/step - loss: 0.1084 - accuracy: 0.9619\n",
      "Epoch 71/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0897 - accuracy: 0.9669\n",
      "Epoch 72/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.1319 - accuracy: 0.9626\n",
      "Epoch 73/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0804 - accuracy: 0.9700\n",
      "Epoch 74/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0860 - accuracy: 0.9685\n",
      "Epoch 75/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.0859 - accuracy: 0.9693\n",
      "Epoch 76/300\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.0889 - accuracy: 0.9679\n",
      "Epoch 77/300\n",
      "1875/1875 [==============================] - 2s 804us/step - loss: 0.0900 - accuracy: 0.9685\n",
      "Epoch 78/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.0835 - accuracy: 0.9693\n",
      "Epoch 79/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.1050 - accuracy: 0.9631\n",
      "Epoch 80/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0826 - accuracy: 0.9700\n",
      "Epoch 81/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0871 - accuracy: 0.9681\n",
      "Epoch 82/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0882 - accuracy: 0.9693\n",
      "Epoch 83/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0856 - accuracy: 0.9691\n",
      "Epoch 84/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.1042 - accuracy: 0.9638\n",
      "Epoch 85/300\n",
      "1875/1875 [==============================] - 1s 751us/step - loss: 0.0787 - accuracy: 0.9718\n",
      "Epoch 86/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0788 - accuracy: 0.9713\n",
      "Epoch 87/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0910 - accuracy: 0.9688\n",
      "Epoch 88/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.0746 - accuracy: 0.9733\n",
      "Epoch 89/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.0786 - accuracy: 0.9713\n",
      "Epoch 90/300\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.0971 - accuracy: 0.9676\n",
      "Epoch 91/300\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.0717 - accuracy: 0.9744\n",
      "Epoch 92/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0796 - accuracy: 0.9721\n",
      "Epoch 93/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0797 - accuracy: 0.9712\n",
      "Epoch 94/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0746 - accuracy: 0.9737\n",
      "Epoch 95/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0807 - accuracy: 0.9721\n",
      "Epoch 96/300\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0665 - accuracy: 0.9760\n",
      "Epoch 97/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0852 - accuracy: 0.9738\n",
      "Epoch 98/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0801 - accuracy: 0.9724\n",
      "Epoch 99/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0939 - accuracy: 0.9712\n",
      "Epoch 100/300\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 0.0699 - accuracy: 0.9764\n",
      "Epoch 101/300\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.0674 - accuracy: 0.9769\n",
      "Epoch 102/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0729 - accuracy: 0.9743\n",
      "Epoch 103/300\n",
      "1875/1875 [==============================] - 2s 813us/step - loss: 0.0775 - accuracy: 0.9744\n",
      "Epoch 104/300\n",
      "1875/1875 [==============================] - 1s 748us/step - loss: 0.0862 - accuracy: 0.9703\n",
      "Epoch 105/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0920 - accuracy: 0.9720\n",
      "Epoch 106/300\n",
      "1875/1875 [==============================] - 2s 866us/step - loss: 0.0689 - accuracy: 0.9759\n",
      "Epoch 107/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0699 - accuracy: 0.9768\n",
      "Epoch 108/300\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.0633 - accuracy: 0.9779\n",
      "Epoch 109/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0629 - accuracy: 0.9776\n",
      "Epoch 110/300\n",
      "1875/1875 [==============================] - 1s 780us/step - loss: 0.0671 - accuracy: 0.9771\n",
      "Epoch 111/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0775 - accuracy: 0.9732\n",
      "Epoch 112/300\n",
      "1875/1875 [==============================] - 1s 782us/step - loss: 0.0890 - accuracy: 0.9704\n",
      "Epoch 113/300\n",
      "1875/1875 [==============================] - 2s 817us/step - loss: 0.0594 - accuracy: 0.9794\n",
      "Epoch 114/300\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.0604 - accuracy: 0.9788\n",
      "Epoch 115/300\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.0753 - accuracy: 0.9761\n",
      "Epoch 116/300\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0833 - accuracy: 0.9747\n",
      "Epoch 117/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0637 - accuracy: 0.9801\n",
      "Epoch 118/300\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.0803 - accuracy: 0.9780\n",
      "Epoch 119/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0649 - accuracy: 0.9796\n",
      "Epoch 120/300\n",
      "1875/1875 [==============================] - 1s 744us/step - loss: 0.0570 - accuracy: 0.9816\n",
      "Epoch 121/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.1080 - accuracy: 0.9736\n",
      "Epoch 122/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0945 - accuracy: 0.9688\n",
      "Epoch 123/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0792 - accuracy: 0.9762\n",
      "Epoch 124/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0557 - accuracy: 0.9827\n",
      "Epoch 125/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0498 - accuracy: 0.9826\n",
      "Epoch 126/300\n",
      "1875/1875 [==============================] - 1s 757us/step - loss: 0.0577 - accuracy: 0.9804\n",
      "Epoch 127/300\n",
      "1875/1875 [==============================] - 1s 780us/step - loss: 0.0640 - accuracy: 0.9803\n",
      "Epoch 128/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0651 - accuracy: 0.9797\n",
      "Epoch 129/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.0951 - accuracy: 0.9696\n",
      "Epoch 130/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0446 - accuracy: 0.9847\n",
      "Epoch 131/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.0772 - accuracy: 0.9748\n",
      "Epoch 132/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0665 - accuracy: 0.9804\n",
      "Epoch 133/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0470 - accuracy: 0.9838\n",
      "Epoch 134/300\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.0531 - accuracy: 0.9817\n",
      "Epoch 135/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0523 - accuracy: 0.9818\n",
      "Epoch 136/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0581 - accuracy: 0.9804\n",
      "Epoch 137/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0592 - accuracy: 0.9793\n",
      "Epoch 138/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.0562 - accuracy: 0.9817\n",
      "Epoch 139/300\n",
      "1875/1875 [==============================] - 1s 760us/step - loss: 0.0713 - accuracy: 0.9789\n",
      "Epoch 140/300\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.0563 - accuracy: 0.9819\n",
      "Epoch 141/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0727 - accuracy: 0.9813\n",
      "Epoch 142/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0615 - accuracy: 0.9814\n",
      "Epoch 143/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0477 - accuracy: 0.9839\n",
      "Epoch 144/300\n",
      "1875/1875 [==============================] - 1s 748us/step - loss: 0.0538 - accuracy: 0.9826\n",
      "Epoch 145/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0545 - accuracy: 0.9822\n",
      "Epoch 146/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.0776 - accuracy: 0.9819\n",
      "Epoch 147/300\n",
      "1875/1875 [==============================] - 1s 734us/step - loss: 0.0776 - accuracy: 0.9770\n",
      "Epoch 148/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.0410 - accuracy: 0.9855\n",
      "Epoch 149/300\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.0684 - accuracy: 0.9786\n",
      "Epoch 150/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.0588 - accuracy: 0.9805\n",
      "Epoch 151/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.0612 - accuracy: 0.9801\n",
      "Epoch 152/300\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.0704 - accuracy: 0.9822\n",
      "Epoch 153/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0572 - accuracy: 0.9826\n",
      "Epoch 154/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0539 - accuracy: 0.9833\n",
      "Epoch 155/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0486 - accuracy: 0.9847\n",
      "Epoch 156/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.0622 - accuracy: 0.9827\n",
      "Epoch 157/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.0660 - accuracy: 0.9794\n",
      "Epoch 158/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0515 - accuracy: 0.9836\n",
      "Epoch 159/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0471 - accuracy: 0.9848\n",
      "Epoch 160/300\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.0548 - accuracy: 0.9832\n",
      "Epoch 161/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0757 - accuracy: 0.9793\n",
      "Epoch 162/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0537 - accuracy: 0.9832\n",
      "Epoch 163/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0576 - accuracy: 0.9832\n",
      "Epoch 164/300\n",
      "1875/1875 [==============================] - 1s 741us/step - loss: 0.0437 - accuracy: 0.9865\n",
      "Epoch 165/300\n",
      "1875/1875 [==============================] - 1s 758us/step - loss: 0.0577 - accuracy: 0.9826\n",
      "Epoch 166/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0606 - accuracy: 0.9820\n",
      "Epoch 167/300\n",
      "1875/1875 [==============================] - 1s 785us/step - loss: 0.0519 - accuracy: 0.9853\n",
      "Epoch 168/300\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0542 - accuracy: 0.9839\n",
      "Epoch 169/300\n",
      "1875/1875 [==============================] - 2s 901us/step - loss: 0.0524 - accuracy: 0.9832\n",
      "Epoch 170/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0724 - accuracy: 0.9800\n",
      "Epoch 171/300\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.4476 - accuracy: 0.9682\n",
      "Epoch 172/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0418 - accuracy: 0.9869\n",
      "Epoch 173/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0354 - accuracy: 0.9885\n",
      "Epoch 174/300\n",
      "1875/1875 [==============================] - 2s 811us/step - loss: 0.0746 - accuracy: 0.9809\n",
      "Epoch 175/300\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.0471 - accuracy: 0.9858\n",
      "Epoch 176/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0891 - accuracy: 0.9759\n",
      "Epoch 177/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0617 - accuracy: 0.9822\n",
      "Epoch 178/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0494 - accuracy: 0.9854\n",
      "Epoch 179/300\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.0791 - accuracy: 0.9772\n",
      "Epoch 180/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0524 - accuracy: 0.9836\n",
      "Epoch 181/300\n",
      "1875/1875 [==============================] - 1s 735us/step - loss: 0.0974 - accuracy: 0.9783\n",
      "Epoch 182/300\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.0537 - accuracy: 0.9867\n",
      "Epoch 183/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.1020 - accuracy: 0.9790\n",
      "Epoch 184/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0859 - accuracy: 0.9758\n",
      "Epoch 185/300\n",
      "1875/1875 [==============================] - 1s 731us/step - loss: 0.0670 - accuracy: 0.9821\n",
      "Epoch 186/300\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.0414 - accuracy: 0.9879\n",
      "Epoch 187/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0291 - accuracy: 0.9900\n",
      "Epoch 188/300\n",
      "1875/1875 [==============================] - 1s 755us/step - loss: 0.0909 - accuracy: 0.9751\n",
      "Epoch 189/300\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3299 - accuracy: 0.9732\n",
      "Epoch 190/300\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.0699 - accuracy: 0.9801\n",
      "Epoch 191/300\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.0413 - accuracy: 0.9864\n",
      "Epoch 192/300\n",
      "1875/1875 [==============================] - 1s 754us/step - loss: 0.0608 - accuracy: 0.9823\n",
      "Epoch 193/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0386 - accuracy: 0.9880\n",
      "Epoch 194/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0396 - accuracy: 0.9876\n",
      "Epoch 195/300\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.0491 - accuracy: 0.9850\n",
      "Epoch 196/300\n",
      "1875/1875 [==============================] - 2s 917us/step - loss: 0.0761 - accuracy: 0.9814\n",
      "Epoch 197/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0589 - accuracy: 0.9874\n",
      "Epoch 198/300\n",
      "1875/1875 [==============================] - 1s 752us/step - loss: 0.0654 - accuracy: 0.9828\n",
      "Epoch 199/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0402 - accuracy: 0.9878\n",
      "Epoch 200/300\n",
      "1875/1875 [==============================] - 1s 764us/step - loss: 0.0891 - accuracy: 0.9782\n",
      "Epoch 201/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.0439 - accuracy: 0.9867\n",
      "Epoch 202/300\n",
      "1875/1875 [==============================] - 2s 812us/step - loss: 0.0863 - accuracy: 0.9834\n",
      "Epoch 203/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0821 - accuracy: 0.9773\n",
      "Epoch 204/300\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.0534 - accuracy: 0.9830\n",
      "Epoch 205/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.0405 - accuracy: 0.9871\n",
      "Epoch 206/300\n",
      "1875/1875 [==============================] - 2s 802us/step - loss: 0.0502 - accuracy: 0.9849\n",
      "Epoch 207/300\n",
      "1875/1875 [==============================] - 1s 740us/step - loss: 0.0497 - accuracy: 0.9853\n",
      "Epoch 208/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0453 - accuracy: 0.9870\n",
      "Epoch 209/300\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.0814 - accuracy: 0.9784\n",
      "Epoch 210/300\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.0398 - accuracy: 0.9888\n",
      "Epoch 211/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0359 - accuracy: 0.9890\n",
      "Epoch 212/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0692 - accuracy: 0.9848\n",
      "Epoch 213/300\n",
      "1875/1875 [==============================] - 1s 795us/step - loss: 0.0360 - accuracy: 0.9894\n",
      "Epoch 214/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0469 - accuracy: 0.9872\n",
      "Epoch 215/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0442 - accuracy: 0.9882\n",
      "Epoch 216/300\n",
      "1875/1875 [==============================] - 1s 753us/step - loss: 0.0762 - accuracy: 0.9765\n",
      "Epoch 217/300\n",
      "1875/1875 [==============================] - 2s 803us/step - loss: 0.0537 - accuracy: 0.9851\n",
      "Epoch 218/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.0328 - accuracy: 0.9906\n",
      "Epoch 219/300\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0629 - accuracy: 0.9826\n",
      "Epoch 220/300\n",
      "1875/1875 [==============================] - 1s 790us/step - loss: 0.0399 - accuracy: 0.9885\n",
      "Epoch 221/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0979 - accuracy: 0.9751\n",
      "Epoch 222/300\n",
      "1875/1875 [==============================] - 2s 807us/step - loss: 0.0380 - accuracy: 0.9884\n",
      "Epoch 223/300\n",
      "1875/1875 [==============================] - 1s 759us/step - loss: 0.0307 - accuracy: 0.9912\n",
      "Epoch 224/300\n",
      "1875/1875 [==============================] - 1s 749us/step - loss: 0.0981 - accuracy: 0.9765\n",
      "Epoch 225/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0672 - accuracy: 0.9815\n",
      "Epoch 226/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0761 - accuracy: 0.9815\n",
      "Epoch 227/300\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0594 - accuracy: 0.9869\n",
      "Epoch 228/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0383 - accuracy: 0.9881\n",
      "Epoch 229/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0532 - accuracy: 0.9867\n",
      "Epoch 230/300\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.0324 - accuracy: 0.9905\n",
      "Epoch 231/300\n",
      "1875/1875 [==============================] - 1s 798us/step - loss: 0.0514 - accuracy: 0.9879\n",
      "Epoch 232/300\n",
      "1875/1875 [==============================] - 1s 768us/step - loss: 0.0259 - accuracy: 0.9921\n",
      "Epoch 233/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0766 - accuracy: 0.9818\n",
      "Epoch 234/300\n",
      "1875/1875 [==============================] - 1s 752us/step - loss: 0.0590 - accuracy: 0.9825\n",
      "Epoch 235/300\n",
      "1875/1875 [==============================] - 1s 771us/step - loss: 0.0257 - accuracy: 0.9920\n",
      "Epoch 236/300\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.0617 - accuracy: 0.9848\n",
      "Epoch 237/300\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.0629 - accuracy: 0.9891\n",
      "Epoch 238/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.0622 - accuracy: 0.9830\n",
      "Epoch 239/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0736 - accuracy: 0.9867\n",
      "Epoch 240/300\n",
      "1875/1875 [==============================] - 1s 730us/step - loss: 0.0683 - accuracy: 0.9833\n",
      "Epoch 241/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.0373 - accuracy: 0.9908\n",
      "Epoch 242/300\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.1379 - accuracy: 0.9751\n",
      "Epoch 243/300\n",
      "1875/1875 [==============================] - 1s 791us/step - loss: 0.0377 - accuracy: 0.9879\n",
      "Epoch 244/300\n",
      "1875/1875 [==============================] - 1s 781us/step - loss: 0.0296 - accuracy: 0.9919\n",
      "Epoch 245/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.1026 - accuracy: 0.9731\n",
      "Epoch 246/300\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0311 - accuracy: 0.9905\n",
      "Epoch 247/300\n",
      "1875/1875 [==============================] - 1s 797us/step - loss: 0.0273 - accuracy: 0.9917\n",
      "Epoch 248/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.1171 - accuracy: 0.9723\n",
      "Epoch 249/300\n",
      "1875/1875 [==============================] - 2s 808us/step - loss: 0.0866 - accuracy: 0.9822\n",
      "Epoch 250/300\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.0316 - accuracy: 0.9913\n",
      "Epoch 251/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.0343 - accuracy: 0.9896\n",
      "Epoch 252/300\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0558 - accuracy: 0.9859\n",
      "Epoch 253/300\n",
      "1875/1875 [==============================] - 1s 774us/step - loss: 0.0433 - accuracy: 0.9885\n",
      "Epoch 254/300\n",
      "1875/1875 [==============================] - 1s 786us/step - loss: 0.0810 - accuracy: 0.9779\n",
      "Epoch 255/300\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.0289 - accuracy: 0.9911\n",
      "Epoch 256/300\n",
      "1875/1875 [==============================] - 1s 772us/step - loss: 0.0461 - accuracy: 0.9882\n",
      "Epoch 257/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0326 - accuracy: 0.9908\n",
      "Epoch 258/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.2912 - accuracy: 0.9589\n",
      "Epoch 259/300\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.3262 - accuracy: 0.9641\n",
      "Epoch 260/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.0654 - accuracy: 0.9825\n",
      "Epoch 261/300\n",
      "1875/1875 [==============================] - 1s 792us/step - loss: 0.0317 - accuracy: 0.9901\n",
      "Epoch 262/300\n",
      "1875/1875 [==============================] - 1s 793us/step - loss: 0.0406 - accuracy: 0.9884\n",
      "Epoch 263/300\n",
      "1875/1875 [==============================] - 1s 770us/step - loss: 0.1237 - accuracy: 0.9681\n",
      "Epoch 264/300\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0728 - accuracy: 0.9809\n",
      "Epoch 265/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0426 - accuracy: 0.9867\n",
      "Epoch 266/300\n",
      "1875/1875 [==============================] - 2s 944us/step - loss: 0.0320 - accuracy: 0.9908\n",
      "Epoch 267/300\n",
      "1875/1875 [==============================] - 2s 966us/step - loss: 0.0835 - accuracy: 0.9796\n",
      "Epoch 268/300\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.0329 - accuracy: 0.9907\n",
      "Epoch 269/300\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.1225 - accuracy: 0.9768\n",
      "Epoch 270/300\n",
      "1875/1875 [==============================] - 1s 789us/step - loss: 0.0327 - accuracy: 0.9899\n",
      "Epoch 271/300\n",
      "1875/1875 [==============================] - 1s 788us/step - loss: 0.0242 - accuracy: 0.9929\n",
      "Epoch 272/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.0313 - accuracy: 0.9909\n",
      "Epoch 273/300\n",
      "1875/1875 [==============================] - 1s 776us/step - loss: 0.0741 - accuracy: 0.9806\n",
      "Epoch 274/300\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.1138 - accuracy: 0.9732\n",
      "Epoch 275/300\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.1080 - accuracy: 0.9745\n",
      "Epoch 276/300\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0331 - accuracy: 0.9903\n",
      "Epoch 277/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0498 - accuracy: 0.9866\n",
      "Epoch 278/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.0314 - accuracy: 0.9909\n",
      "Epoch 279/300\n",
      "1875/1875 [==============================] - 1s 777us/step - loss: 0.0715 - accuracy: 0.9820\n",
      "Epoch 280/300\n",
      "1875/1875 [==============================] - 1s 783us/step - loss: 0.2184 - accuracy: 0.9581\n",
      "Epoch 281/300\n",
      "1875/1875 [==============================] - 1s 742us/step - loss: 0.0589 - accuracy: 0.9827\n",
      "Epoch 282/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.0924 - accuracy: 0.9764\n",
      "Epoch 283/300\n",
      "1875/1875 [==============================] - 2s 800us/step - loss: 0.0269 - accuracy: 0.9915\n",
      "Epoch 284/300\n",
      "1875/1875 [==============================] - 1s 796us/step - loss: 0.0299 - accuracy: 0.9915\n",
      "Epoch 285/300\n",
      "1875/1875 [==============================] - 1s 787us/step - loss: 0.3278 - accuracy: 0.9522\n",
      "Epoch 286/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.3545 - accuracy: 0.9666\n",
      "Epoch 287/300\n",
      "1875/1875 [==============================] - 2s 860us/step - loss: 0.0424 - accuracy: 0.9862\n",
      "Epoch 288/300\n",
      "1875/1875 [==============================] - 1s 761us/step - loss: 0.0270 - accuracy: 0.9916\n",
      "Epoch 289/300\n",
      "1875/1875 [==============================] - 1s 766us/step - loss: 0.0393 - accuracy: 0.9890\n",
      "Epoch 290/300\n",
      "1875/1875 [==============================] - 1s 769us/step - loss: 0.0383 - accuracy: 0.9899\n",
      "Epoch 291/300\n",
      "1875/1875 [==============================] - 1s 778us/step - loss: 0.0889 - accuracy: 0.9825\n",
      "Epoch 292/300\n",
      "1875/1875 [==============================] - 1s 762us/step - loss: 0.0487 - accuracy: 0.9874\n",
      "Epoch 293/300\n",
      "1875/1875 [==============================] - 1s 794us/step - loss: 0.0313 - accuracy: 0.9910\n",
      "Epoch 294/300\n",
      "1875/1875 [==============================] - 2s 809us/step - loss: 0.0706 - accuracy: 0.9831\n",
      "Epoch 295/300\n",
      "1875/1875 [==============================] - 1s 779us/step - loss: 0.0439 - accuracy: 0.9872\n",
      "Epoch 296/300\n",
      "1875/1875 [==============================] - 1s 765us/step - loss: 0.0452 - accuracy: 0.9896\n",
      "Epoch 297/300\n",
      "1875/1875 [==============================] - 1s 784us/step - loss: 0.0816 - accuracy: 0.9820\n",
      "Epoch 298/300\n",
      "1875/1875 [==============================] - 2s 801us/step - loss: 0.0355 - accuracy: 0.9912\n",
      "Epoch 299/300\n",
      "1875/1875 [==============================] - 2s 815us/step - loss: 0.0238 - accuracy: 0.9932\n",
      "Epoch 300/300\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.0371 - accuracy: 0.9898\n",
      "7min 23s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "with tf.device('/GPU:0'):\n",
    "    gpu_model = get_model(hidden_layers=5)\n",
    "    gpu_model.fit(train_images_scaled, train_labels, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03381e52-b797-4773-a2a5-b5fb591274a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
